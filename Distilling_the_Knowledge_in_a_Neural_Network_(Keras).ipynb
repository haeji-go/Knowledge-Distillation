{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "st0Bc_JfHqM4"
   },
   "source": [
    "## 빅데이터기획분석론 논문리뷰과제 (구현체실습)\n",
    "선정 논문 : Distilling the Knowledge in a Neural Network <br>\n",
    "실험 환경 : CoLab<br>\n",
    "정보융합학부 고해지 <br>\n",
    "2021.12.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMg26nv9A-Qb"
   },
   "source": [
    "# Knowledge Distillation\n",
    "\n",
    "**Description:** Implementation of classical Knowledge Distillation.<br>\n",
    "**Reference:** \"Distilling the Knowledge in a Neural Network\" (https://arxiv.org/abs/1503.02531) <br>\n",
    "**source code:** https://keras.io/examples/vision/knowledge_distillation/#distill-teacher-to-student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEFbOxM_A-Qj"
   },
   "source": [
    "## Setup\n",
    "필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5xU54gPdA-Qk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD_XJkqDA-Qm"
   },
   "source": [
    "## `Distiller()` 클래스 정의\n",
    "\n",
    "사용자 정의 클래스 `Distiller()`\n",
    "  `keras.Model`을 상속하여 `train_step`, `test_step`, `compile()` override하여 사용. <br> <br>\n",
    "\n",
    "**[distiller를 사용하기위해 필요한 사항들]**\n",
    "\n",
    "- A trained teacher model <br>\n",
    "  훈련된 교사모델 <- large model\n",
    "- A student model to train <br> \n",
    "  훈련할 학생모델 <- small model\n",
    "- A student loss function on the difference between student predictions and ground-truth<br> \n",
    "  학생모델에 대한 loss 함수 : 학생모델의 예측값과 실제정답의 차\n",
    "- A distillation loss function, along with a `temperature`, on the difference between the soft student predictions and the soft teacher labels <br> \n",
    "  distillation loss 함수 : 학생모델이 예측한 soft 값과 교사모델이 예측한 soft 값(logit)\n",
    "- An `alpha` factor to weight the student and distillation loss <br> \n",
    "  `alpha` : 학생 loss와 distillation loss에서의 가중치\n",
    "- An optimizer for the student and (optional) metrics to evaluate performance <br> \n",
    "  학생모델을 위한 최적화 도구, 성능을 평가하기 위한 metrics\n",
    "\n",
    "<br>\n",
    "\n",
    "**[`train_step`]** <br>\n",
    "교사모델과 학생모델에 대해 전진패스(backward pass) 수행 (학습) <br>\n",
    "alpha를 이용하여 loss 계산 (loss = student_loss + distillation_loss) <br>\n",
    "학생모델의 weight에 대한 기울기(gradient) 계산하기위해 후진패스(backward pass) <br>\n",
    "\n",
    "**[`test_step`]** <br>\n",
    "학생 모델 평가 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8EbGTdKwA-Qn"
   },
   "outputs": [],
   "source": [
    "# Distiller class 정의 \n",
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer, # 학생 가중치를 위한 keras optimizer\n",
    "        metrics, # 평가를 위한 keras metrics\n",
    "        student_loss_fn, #loss: 학생모델 예측-실제정답\n",
    "        distillation_loss_fn, #loss: 학생모델의 soft 예측값-교사모델의 soft예측값\n",
    "        alpha=0.1, #loss에 주는 가중치\n",
    "        temperature=3, #확률분포를 더 부드럽게 하기 위해 사용\n",
    "    ):\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    # 학습 단계\n",
    "    def train_step(self, data):\n",
    "        # Unpack data \n",
    "        x, y = data\n",
    "\n",
    "        # Forward pass of teacher (교사모델의 Forward pass)\n",
    "        teacher_predictions = self.teacher(x, training=False) #학습된 교사모델 사용하므로 False\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student (학생모델의 Forward pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses (loss 계산)\n",
    "            ## 학생모델 loss\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            ## 증류 loss\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            ## alpha 가중치를 적용하여 최종 loss 계산\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Compute gradients (기울기 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights (가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`. \n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance (수행에 대한 결과를 dictionary로 반환)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    # 테스트 단계 ; 학생모델 평가\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions (예측값 계산)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss (loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics. (성능지표 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance (수행에 대한 결과를 dictionary로 반환)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vspMPPvA-Qo"
   },
   "source": [
    "## 학생모델(student model) 및 교사모델(teacher model) 생성\n",
    "교사모델을 만들고, 더 작은 학생모델을 만든다.  <br>\n",
    "두 모델 모두 컨볼루션 신경망(CNN)이다.<br>\n",
    "아래의 코드에서는 Sequential()을 사용했지만, 어느 Keras model이든 사용가능하다.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kVMzMp2GA-Qp"
   },
   "outputs": [],
   "source": [
    "# 교사모델(teacher model) 생성\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"), # 256개의 convolution filter 사용\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"), # 512개의 convolution filter 사용\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# 학생모델(student model) 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"), # 16개의 convolution filter 사용 (256개인 teacher model보다 smaller)\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"), # 32개의 convolution filter 사용 (512개인 teacher model보다 smaller)\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "\n",
    "# 나중에 비교를 위해 학생모델(student model) 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co1NjCRTA-Qq"
   },
   "source": [
    "## DataSet 준비\n",
    "\n",
    "교사모델을 학습시키고, 교사모델을 distilling하는데 사용하는 데이터셋 : **MNIST** https://keras.io/api/datasets/mnist/) <br>\n",
    "(다른 dataset도 동일한 절차로 적절한 모델을 선택하여 진행하면 됨 ex.CIFAR-10) <br>\n",
    "\n",
    "학생모델과 교사모델 모두 training set으로 학습되고, test set으로 평가된다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "dfU0hj3BA-Qr",
    "outputId": "df5e7015-dda1-473a-8e7f-854d6d612956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# train dataset, test dataset 준비\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# train data 정규화 (Nomalization)\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "# test data 정규화 (Nomalization)\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDRuF093A-Qr"
   },
   "source": [
    "## 교사모델(teacher model) 학습\n",
    "지식증류에서, 교사모델이 학습되고 고정되었다고 가정함 <br>\n",
    "--> 일반적인 방법으로 교사모델 학습시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8CqTkdaKA-Qs",
    "outputId": "498b2d00-63e3-4448-9e1d-6d763417906f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 575s 306ms/step - loss: 0.1423 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 567s 302ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9723\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 633s 338ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 609s 325ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9791\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 592s 316ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9808\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10237742960453033, 0.9729999899864197]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일반적인 방식으로 교사모델(teacher model)학습\n",
    "teacher.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# 학습 및 data로 교사모델(teacher model)의 성능 확인\n",
    "teacher.fit(x_train, y_train, epochs=5)\n",
    "teacher.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maGa6TBTA-Qs"
   },
   "source": [
    "## 교사모델(teacher model)에서 학생모델(student model)로 증류(distilling)\n",
    "교사모델 : 이미 학습이 완료된 상태 <br>\n",
    "`Distiller(student, teacher)` 인스턴스를  초기화 및 컴파일`compile()` 진행<br>\n",
    "(loss함수, 하이퍼파라미터, optimizer 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3ptVvh7A-Qt",
    "outputId": "f5cef234-47c2-4e68-f90f-0da7154ea185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 152s 81ms/step - sparse_categorical_accuracy: 0.9199 - student_loss: 0.3386 - distillation_loss: 0.0943\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 151s 81ms/step - sparse_categorical_accuracy: 0.9705 - student_loss: 0.1164 - distillation_loss: 0.0278\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 151s 80ms/step - sparse_categorical_accuracy: 0.9754 - student_loss: 0.0910 - distillation_loss: 0.0209\n",
      "313/313 [==============================] - 1s 4ms/step - sparse_categorical_accuracy: 0.9760 - student_loss: 0.0883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9760000109672546, 0.046132225543260574]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distiller 인스턴스 초기화 및 컴파일\n",
    "distiller = Distiller(student=student, teacher=teacher) # student model과 teacher model 설정\n",
    "\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# 선생모델에서 학생모델로 증류 진행 (distill)\n",
    "distiller.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "# test dataset에 대하여 평가\n",
    "distiller.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zF-VLCxn0oM"
   },
   "source": [
    "**Experiment : Temperature = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAGWjEmKgVxM",
    "outputId": "6466c9f9-4d8f-41f8-845e-7724f27f29c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 153s 81ms/step - sparse_categorical_accuracy: 0.9785 - student_loss: 0.0679 - distillation_loss: 0.0380\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 151s 81ms/step - sparse_categorical_accuracy: 0.9798 - student_loss: 0.0629 - distillation_loss: 0.0309\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 152s 81ms/step - sparse_categorical_accuracy: 0.9791 - student_loss: 0.0620 - distillation_loss: 0.0272\n",
      "313/313 [==============================] - 1s 4ms/step - sparse_categorical_accuracy: 0.9754 - student_loss: 0.0811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9753999710083008, 0.010427047498524189]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distiller 인스턴스 초기화 및 컴파일\n",
    "distiller_temp1 = Distiller(student=student, teacher=teacher) # student model과 teacher model 설정\n",
    "\n",
    "distiller_temp1.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "# 선생모델에서 학생모델로 증류 진행 (distill)\n",
    "distiller_temp1.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "# test dataset에 대하여 평가\n",
    "distiller_temp1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chw_pcPboEBE"
   },
   "source": [
    "**Experiment : Temperature = 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41YpIdTejdUZ",
    "outputId": "7b5ec453-1819-4177-cf6b-cece4c4a867e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 155s 82ms/step - sparse_categorical_accuracy: 0.9808 - student_loss: 0.0639 - distillation_loss: 0.0195\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 153s 81ms/step - sparse_categorical_accuracy: 0.9821 - student_loss: 0.0607 - distillation_loss: 0.0176\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 153s 82ms/step - sparse_categorical_accuracy: 0.9823 - student_loss: 0.0583 - distillation_loss: 0.0166\n",
      "313/313 [==============================] - 1s 4ms/step - sparse_categorical_accuracy: 0.9788 - student_loss: 0.0799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9787999987602234, 0.00665842043235898]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distiller 인스턴스 초기화 및 컴파일\n",
    "distiller_temp5 = Distiller(student=student, teacher=teacher) # student model과 teacher model 설정\n",
    "\n",
    "distiller_temp5.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=5,\n",
    ")\n",
    "\n",
    "# 선생모델에서 학생모델로 증류 진행 (distill)\n",
    "distiller_temp5.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "# test dataset에 대하여 평가\n",
    "distiller_temp5.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJ2_siroKWq"
   },
   "source": [
    "**Experiment : alpha=0.7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYtd1-l3oJbn",
    "outputId": "9e51eeab-922c-497c-c563-59f7c036ca93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 153s 81ms/step - sparse_categorical_accuracy: 0.9847 - student_loss: 0.0500 - distillation_loss: 0.0103\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 153s 82ms/step - sparse_categorical_accuracy: 0.9855 - student_loss: 0.0471 - distillation_loss: 0.0099\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 153s 82ms/step - sparse_categorical_accuracy: 0.9859 - student_loss: 0.0444 - distillation_loss: 0.0096\n",
      "313/313 [==============================] - 1s 4ms/step - sparse_categorical_accuracy: 0.9799 - student_loss: 0.0730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9799000024795532, 0.0017649412620812654]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distiller 인스턴스 초기화 및 컴파일\n",
    "distiller_alpha7 = Distiller(student=student, teacher=teacher) # student model과 teacher model 설정\n",
    "\n",
    "distiller_alpha7.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# 선생모델에서 학생모델로 증류 진행 (distill)\n",
    "distiller_alpha7.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "# test dataset에 대하여 평가\n",
    "distiller_alpha7.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG7EEs_zA-Qt"
   },
   "source": [
    "## 일반적인 방식으로 학생모델(student model)학습 (비교를 위해)\n",
    "지식증류에의해 얻어지는 성능을 평가하기위해 <br>\n",
    "동일한 학생모델을 교사모델없이 일반적인 방식으로 학습시킨다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhknQuTaA-Qt",
    "outputId": "e4222a52-9eda-4acf-f62b-07fd31454b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2536 - sparse_categorical_accuracy: 0.9232\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9758\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0697457566857338, 0.977400004863739]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train student as doen usually\n",
    "student_scratch.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train and evaluate student trained from scratch.\n",
    "student_scratch.fit(x_train, y_train, epochs=3)\n",
    "student_scratch.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1YIIE3ZWeSs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Distilling the Knowledge in a Neural Network (Keras)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
